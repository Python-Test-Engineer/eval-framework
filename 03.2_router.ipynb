{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef08971",
   "metadata": {},
   "source": [
    "<img src=\"./images/antrhopic-workflows.png\" width=700px>\n",
    "\n",
    "https://www.anthropic.com/engineering/building-effective-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44f832a",
   "metadata": {},
   "source": [
    "This is the example based on my codebar coaching.\n",
    "\n",
    "We can use an agent to return back the next step as we saw in the JOKE example.\n",
    "\n",
    "We have a list of reports and their uses and a user can ask a question with the agent returning back the most useful report to be run.\n",
    "\n",
    "This can them be processes with more application logic.\n",
    "\n",
    "This is ROUTING or IF/ELSE type decision making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0a2ff2",
   "metadata": {},
   "source": [
    "As we saw in 03 FAQ, we could use this to create a filter for the next agent so that it can be more selective about data retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b9c03",
   "metadata": {},
   "source": [
    "If we combine this ROUTER as a precursor to the FAQ pattern, with one agent selecting the domain, and another agent answering the question.\n",
    "\n",
    "This is a MULTI-AGENT system - we can have a range of design patterns that can be used to create a MULTI-AGENT system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70e39cd8-ec79-4e3e-9c26-5659d42d0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "from pprint import pprint\n",
    "from rich.console import Console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2a30cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "console = Console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16b03111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For variation use a function to get the LLM client based on the user's choice\n",
    "\n",
    "\n",
    "def get_llm_client(llm_choice):\n",
    "\n",
    "    if llm_choice == \"GROQ\":\n",
    "\n",
    "        client = OpenAI(\n",
    "            base_url=\"https://api.groq.com/openai/v1\",\n",
    "            api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    "        )\n",
    "\n",
    "        return client\n",
    "\n",
    "    elif llm_choice == \"OPENAI\":\n",
    "\n",
    "        load_dotenv()  # load environment variables from .env fil\n",
    "\n",
    "        client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "        return client\n",
    "\n",
    "    else:\n",
    "\n",
    "        raise ValueError(\"Invalid LLM choice. Please choose 'GROQ' or 'OPENAI'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "231605aa-fccb-447e-89cf-8b187444536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY exists and begins sk-proj-vIt-L1...\n",
      "GROQ_API_KEY exists and begins gsk_0yKDCuUXkz...\n",
      "LLM_CHOICE: GROQ - MODEL: llama-3.3-70b-versatile\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "LLM_CHOICE = \"OPENAI\"\n",
    "LLM_CHOICE = \"GROQ\"\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    print(f\"OPENAI_API_KEY exists and begins {OPENAI_API_KEY[:14]}...\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY not set\")\n",
    "\n",
    "if GROQ_API_KEY:\n",
    "    print(f\"GROQ_API_KEY exists and begins {GROQ_API_KEY[:14]}...\")\n",
    "else:\n",
    "    print(\"GROQ_API_KEY not set\")\n",
    "\n",
    "\n",
    "client = get_llm_client(LLM_CHOICE)\n",
    "if LLM_CHOICE == \"GROQ\":\n",
    "    MODEL = \"llama-3.3-70b-versatile\"\n",
    "else:\n",
    "    MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "print(f\"LLM_CHOICE: {LLM_CHOICE} - MODEL: {MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11d57e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To clean data use |DATA_CLEANING_AGENT|\n",
      "Total number of data_analysis_agents: 35\n"
     ]
    }
   ],
   "source": [
    "data_analysis_agents = [\n",
    "    \"To clean data use |DATA_CLEANING_AGENT|\",\n",
    "    \"To run analysis on data types use |DATA_TYPES_AGENT|\",\n",
    "    \"To do feature engineering use |FEATURE_ENGINEERING_AGENT|\",\n",
    "    \"To detect outliers use |OUTLIER_DETECTION_AGENT|\",\n",
    "    \"To handle missing values use |MISSING_DATA_AGENT|\",\n",
    "    \"To normalize or standardize features use |SCALING_AGENT|\",\n",
    "    \"To perform correlation analysis use |CORRELATION_AGENT|\",\n",
    "    \"To create visualizations use |VISUALIZATION_AGENT|\",\n",
    "    \"To run statistical tests use |STATISTICAL_TESTING_AGENT|\",\n",
    "    \"To perform dimensionality reduction use |DIMENSION_REDUCTION_AGENT|\",\n",
    "    \"To segment data into clusters use |CLUSTERING_AGENT|\",\n",
    "    \"To build predictive models use |PREDICTIVE_MODELING_AGENT|\",\n",
    "    \"To evaluate model performance use |MODEL_EVALUATION_AGENT|\",\n",
    "    \"To optimize hyperparameters use |HYPERPARAMETER_TUNING_AGENT|\",\n",
    "    \"To handle imbalanced datasets use |CLASS_IMBALANCE_AGENT|\",\n",
    "    \"To implement time series analysis use |TIME_SERIES_AGENT|\",\n",
    "    \"To perform text analysis use |TEXT_ANALYTICS_AGENT|\",\n",
    "    \"To extract insights from geospatial data use |GEOSPATIAL_ANALYSIS_AGENT|\",\n",
    "    \"To process large datasets use |BIG_DATA_PROCESSING_AGENT|\",\n",
    "    \"To create data pipelines use |DATA_PIPELINE_AGENT|\",\n",
    "    \"To generate synthetic data use |SYNTHETIC_DATA_AGENT|\",\n",
    "    \"To implement cross-validation use |CROSS_VALIDATION_AGENT|\",\n",
    "    \"To interpret complex models use |MODEL_INTERPRETATION_AGENT|\",\n",
    "    \"To detect data drift use |DATA_DRIFT_AGENT|\",\n",
    "    \"To run A/B tests use |AB_TESTING_AGENT|\",\n",
    "    \"To prepare data for machine learning use |ML_PREPROCESSING_AGENT|\",\n",
    "    \"To create ensemble models use |ENSEMBLE_MODELING_AGENT|\",\n",
    "    \"To perform anomaly detection use |ANOMALY_DETECTION_AGENT|\",\n",
    "    \"To optimize SQL queries use |SQL_OPTIMIZATION_AGENT|\",\n",
    "    \"To create interactive dashboards use |DASHBOARD_CREATION_AGENT|\",\n",
    "    \"To extract features from images use |IMAGE_FEATURE_AGENT|\",\n",
    "    \"To implement natural language processing use |NLP_AGENT|\",\n",
    "    \"To perform sentiment analysis use |SENTIMENT_ANALYSIS_AGENT|\",\n",
    "    \"To do automated feature selection use |FEATURE_SELECTION_AGENT|\",\n",
    "    \"To generate reports automatically use |AUTOMATED_REPORTING_AGENT|\",\n",
    "]\n",
    "\n",
    "# Access individual tools\n",
    "print(data_analysis_agents[0])  # Prints the first tool\n",
    "\n",
    "# Count total number of data_analysis_agents\n",
    "print(f\"Total number of data_analysis_agents: {len(data_analysis_agents)}\")\n",
    "# Again, 'character and instruction' along with knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1b4d68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A request to the LLM is stateless so we will always need to pass all the data that is needed each time.\n",
    "\n",
    "# `history` is just that - a record of what has gone on before so that the LLM can have context to answer the query.\n",
    "\n",
    "\n",
    "# We will use GRADIO as our UI.\n",
    "def chat(message, history):\n",
    "    # history is part of the gradio ChatInterface and it stores previous answers\n",
    "    messages = (\n",
    "        [{\"role\": \"system\", \"content\": system_message}]\n",
    "        # + history ## groq gives error as it adds metadata\n",
    "        + [{\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "    print(\"History is:\")\n",
    "    console.print(history)\n",
    "    print(\"And messages is:\")\n",
    "    console.print(messages)\n",
    "    # ====================\n",
    "    # AI bit\n",
    "    stream = client.chat.completions.create(\n",
    "        model=MODEL, messages=messages, stream=True, temperature=0.0\n",
    "    )\n",
    "\n",
    "    # Just UI implementation\n",
    "    response = \"\"\n",
    "    for stream_so_far in stream:\n",
    "        response += stream_so_far.choices[0].delta.content or \"\"\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3df916ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a skilled data analyst and data engineer. When asked a question, you will respond with the most relevant data analysis agent from the list below.\n",
    "\n",
    "The data analysis agents are:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7377e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message += \"\\n\" + \"\\n\".join(data_analysis_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adb37b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message += \"\"\"\\nAlso include a reason and return output as JSON with the following structure with the report name as per context given:\n",
    "{\"report\": \" |DATA_TYPES_AGENT|\", \"reason\": \"this is a report aboit sales\"}\n",
    "\n",
    "#ONLY# JSON\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d4acf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e9e4e-7836-43ac-a0c3-e1ab5ed6b136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And messages is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'system'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'\\nYou are a skilled data analyst and data engineer. When asked a question, you will respond </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with the most relevant data analysis agent from the list below.\\n\\nThe data analysis agents are:\\n\\n\\nTo clean data</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">use |DATA_CLEANING_AGENT|\\nTo run analysis on data types use |DATA_TYPES_AGENT|\\nTo do feature engineering use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|FEATURE_ENGINEERING_AGENT|\\nTo detect outliers use |OUTLIER_DETECTION_AGENT|\\nTo handle missing values use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|MISSING_DATA_AGENT|\\nTo normalize or standardize features use |SCALING_AGENT|\\nTo perform correlation analysis use</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|CORRELATION_AGENT|\\nTo create visualizations use |VISUALIZATION_AGENT|\\nTo run statistical tests use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|STATISTICAL_TESTING_AGENT|\\nTo perform dimensionality reduction use |DIMENSION_REDUCTION_AGENT|\\nTo segment data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">into clusters use |CLUSTERING_AGENT|\\nTo build predictive models use |PREDICTIVE_MODELING_AGENT|\\nTo evaluate model</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance use |MODEL_EVALUATION_AGENT|\\nTo optimize hyperparameters use |HYPERPARAMETER_TUNING_AGENT|\\nTo handle </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">imbalanced datasets use |CLASS_IMBALANCE_AGENT|\\nTo implement time series analysis use |TIME_SERIES_AGENT|\\nTo </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">perform text analysis use |TEXT_ANALYTICS_AGENT|\\nTo extract insights from geospatial data use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|GEOSPATIAL_ANALYSIS_AGENT|\\nTo process large datasets use |BIG_DATA_PROCESSING_AGENT|\\nTo create data pipelines </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">use |DATA_PIPELINE_AGENT|\\nTo generate synthetic data use |SYNTHETIC_DATA_AGENT|\\nTo implement cross-validation use</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|CROSS_VALIDATION_AGENT|\\nTo interpret complex models use |MODEL_INTERPRETATION_AGENT|\\nTo detect data drift use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|DATA_DRIFT_AGENT|\\nTo run A/B tests use |AB_TESTING_AGENT|\\nTo prepare data for machine learning use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|ML_PREPROCESSING_AGENT|\\nTo create ensemble models use |ENSEMBLE_MODELING_AGENT|\\nTo perform anomaly detection use</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|ANOMALY_DETECTION_AGENT|\\nTo optimize SQL queries use |SQL_OPTIMIZATION_AGENT|\\nTo create interactive dashboards </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">use |DASHBOARD_CREATION_AGENT|\\nTo extract features from images use |IMAGE_FEATURE_AGENT|\\nTo implement natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language processing use |NLP_AGENT|\\nTo perform sentiment analysis use |SENTIMENT_ANALYSIS_AGENT|\\nTo do automated </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">feature selection use |FEATURE_SELECTION_AGENT|\\nTo generate reports automatically use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|AUTOMATED_REPORTING_AGENT|\\nAlso include a reason and return output as JSON with the following structure with the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">report name as per context given:\\n{\"report\": \" |DATA_TYPES_AGENT|\", \"reason\": \"this is a report aboit </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sales\"}\\n\\n#ONLY# JSON\\n'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'sales for last year'</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'role'\u001b[0m: \u001b[32m'system'\u001b[0m,\n",
       "        \u001b[32m'content'\u001b[0m: \u001b[32m'\\nYou are a skilled data analyst and data engineer. When asked a question, you will respond \u001b[0m\n",
       "\u001b[32mwith the most relevant data analysis agent from the list below.\\n\\nThe data analysis agents are:\\n\\n\\nTo clean data\u001b[0m\n",
       "\u001b[32muse |DATA_CLEANING_AGENT|\\nTo run analysis on data types use |DATA_TYPES_AGENT|\\nTo do feature engineering use \u001b[0m\n",
       "\u001b[32m|FEATURE_ENGINEERING_AGENT|\\nTo detect outliers use |OUTLIER_DETECTION_AGENT|\\nTo handle missing values use \u001b[0m\n",
       "\u001b[32m|MISSING_DATA_AGENT|\\nTo normalize or standardize features use |SCALING_AGENT|\\nTo perform correlation analysis use\u001b[0m\n",
       "\u001b[32m|CORRELATION_AGENT|\\nTo create visualizations use |VISUALIZATION_AGENT|\\nTo run statistical tests use \u001b[0m\n",
       "\u001b[32m|STATISTICAL_TESTING_AGENT|\\nTo perform dimensionality reduction use |DIMENSION_REDUCTION_AGENT|\\nTo segment data \u001b[0m\n",
       "\u001b[32minto clusters use |CLUSTERING_AGENT|\\nTo build predictive models use |PREDICTIVE_MODELING_AGENT|\\nTo evaluate model\u001b[0m\n",
       "\u001b[32mperformance use |MODEL_EVALUATION_AGENT|\\nTo optimize hyperparameters use |HYPERPARAMETER_TUNING_AGENT|\\nTo handle \u001b[0m\n",
       "\u001b[32mimbalanced datasets use |CLASS_IMBALANCE_AGENT|\\nTo implement time series analysis use |TIME_SERIES_AGENT|\\nTo \u001b[0m\n",
       "\u001b[32mperform text analysis use |TEXT_ANALYTICS_AGENT|\\nTo extract insights from geospatial data use \u001b[0m\n",
       "\u001b[32m|GEOSPATIAL_ANALYSIS_AGENT|\\nTo process large datasets use |BIG_DATA_PROCESSING_AGENT|\\nTo create data pipelines \u001b[0m\n",
       "\u001b[32muse |DATA_PIPELINE_AGENT|\\nTo generate synthetic data use |SYNTHETIC_DATA_AGENT|\\nTo implement cross-validation use\u001b[0m\n",
       "\u001b[32m|CROSS_VALIDATION_AGENT|\\nTo interpret complex models use |MODEL_INTERPRETATION_AGENT|\\nTo detect data drift use \u001b[0m\n",
       "\u001b[32m|DATA_DRIFT_AGENT|\\nTo run A/B tests use |AB_TESTING_AGENT|\\nTo prepare data for machine learning use \u001b[0m\n",
       "\u001b[32m|ML_PREPROCESSING_AGENT|\\nTo create ensemble models use |ENSEMBLE_MODELING_AGENT|\\nTo perform anomaly detection use\u001b[0m\n",
       "\u001b[32m|ANOMALY_DETECTION_AGENT|\\nTo optimize SQL queries use |SQL_OPTIMIZATION_AGENT|\\nTo create interactive dashboards \u001b[0m\n",
       "\u001b[32muse |DASHBOARD_CREATION_AGENT|\\nTo extract features from images use |IMAGE_FEATURE_AGENT|\\nTo implement natural \u001b[0m\n",
       "\u001b[32mlanguage processing use |NLP_AGENT|\\nTo perform sentiment analysis use |SENTIMENT_ANALYSIS_AGENT|\\nTo do automated \u001b[0m\n",
       "\u001b[32mfeature selection use |FEATURE_SELECTION_AGENT|\\nTo generate reports automatically use \u001b[0m\n",
       "\u001b[32m|AUTOMATED_REPORTING_AGENT|\\nAlso include a reason and return output as JSON with the following structure with the \u001b[0m\n",
       "\u001b[32mreport name as per context given:\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"report\": \" |DATA_TYPES_AGENT|\", \"reason\": \"this is a report aboit \u001b[0m\n",
       "\u001b[32msales\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n#ONLY# JSON\\n'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'sales for last year'\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'metadata'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'sales for last year'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'options'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'metadata'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"report\": \"VISUALIZATION_AGENT\", \"reason\": \"to analyze and visualize sales data for the last </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">year\"}'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'options'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'metadata'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'sales for last year'\u001b[0m, \u001b[32m'options'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "        \u001b[32m'metadata'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'content'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"report\": \"VISUALIZATION_AGENT\", \"reason\": \"to analyze and visualize sales data for the last \u001b[0m\n",
       "\u001b[32myear\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "        \u001b[32m'options'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And messages is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'system'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'\\nYou are a skilled data analyst and data engineer. When asked a question, you will respond </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with the most relevant data analysis agent from the list below.\\n\\nThe data analysis agents are:\\n\\n\\nTo clean data</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">use |DATA_CLEANING_AGENT|\\nTo run analysis on data types use |DATA_TYPES_AGENT|\\nTo do feature engineering use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|FEATURE_ENGINEERING_AGENT|\\nTo detect outliers use |OUTLIER_DETECTION_AGENT|\\nTo handle missing values use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|MISSING_DATA_AGENT|\\nTo normalize or standardize features use |SCALING_AGENT|\\nTo perform correlation analysis use</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|CORRELATION_AGENT|\\nTo create visualizations use |VISUALIZATION_AGENT|\\nTo run statistical tests use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|STATISTICAL_TESTING_AGENT|\\nTo perform dimensionality reduction use |DIMENSION_REDUCTION_AGENT|\\nTo segment data </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">into clusters use |CLUSTERING_AGENT|\\nTo build predictive models use |PREDICTIVE_MODELING_AGENT|\\nTo evaluate model</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance use |MODEL_EVALUATION_AGENT|\\nTo optimize hyperparameters use |HYPERPARAMETER_TUNING_AGENT|\\nTo handle </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">imbalanced datasets use |CLASS_IMBALANCE_AGENT|\\nTo implement time series analysis use |TIME_SERIES_AGENT|\\nTo </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">perform text analysis use |TEXT_ANALYTICS_AGENT|\\nTo extract insights from geospatial data use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|GEOSPATIAL_ANALYSIS_AGENT|\\nTo process large datasets use |BIG_DATA_PROCESSING_AGENT|\\nTo create data pipelines </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">use |DATA_PIPELINE_AGENT|\\nTo generate synthetic data use |SYNTHETIC_DATA_AGENT|\\nTo implement cross-validation use</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|CROSS_VALIDATION_AGENT|\\nTo interpret complex models use |MODEL_INTERPRETATION_AGENT|\\nTo detect data drift use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|DATA_DRIFT_AGENT|\\nTo run A/B tests use |AB_TESTING_AGENT|\\nTo prepare data for machine learning use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|ML_PREPROCESSING_AGENT|\\nTo create ensemble models use |ENSEMBLE_MODELING_AGENT|\\nTo perform anomaly detection use</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|ANOMALY_DETECTION_AGENT|\\nTo optimize SQL queries use |SQL_OPTIMIZATION_AGENT|\\nTo create interactive dashboards </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">use |DASHBOARD_CREATION_AGENT|\\nTo extract features from images use |IMAGE_FEATURE_AGENT|\\nTo implement natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language processing use |NLP_AGENT|\\nTo perform sentiment analysis use |SENTIMENT_ANALYSIS_AGENT|\\nTo do automated </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">feature selection use |FEATURE_SELECTION_AGENT|\\nTo generate reports automatically use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">|AUTOMATED_REPORTING_AGENT|\\nAlso include a reason and return output as JSON with the following structure with the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">report name as per context given:\\n{\"report\": \" |DATA_TYPES_AGENT|\", \"reason\": \"this is a report aboit </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sales\"}\\n\\n#ONLY# JSON\\n'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'i want to have cross validation data '</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'role'\u001b[0m: \u001b[32m'system'\u001b[0m,\n",
       "        \u001b[32m'content'\u001b[0m: \u001b[32m'\\nYou are a skilled data analyst and data engineer. When asked a question, you will respond \u001b[0m\n",
       "\u001b[32mwith the most relevant data analysis agent from the list below.\\n\\nThe data analysis agents are:\\n\\n\\nTo clean data\u001b[0m\n",
       "\u001b[32muse |DATA_CLEANING_AGENT|\\nTo run analysis on data types use |DATA_TYPES_AGENT|\\nTo do feature engineering use \u001b[0m\n",
       "\u001b[32m|FEATURE_ENGINEERING_AGENT|\\nTo detect outliers use |OUTLIER_DETECTION_AGENT|\\nTo handle missing values use \u001b[0m\n",
       "\u001b[32m|MISSING_DATA_AGENT|\\nTo normalize or standardize features use |SCALING_AGENT|\\nTo perform correlation analysis use\u001b[0m\n",
       "\u001b[32m|CORRELATION_AGENT|\\nTo create visualizations use |VISUALIZATION_AGENT|\\nTo run statistical tests use \u001b[0m\n",
       "\u001b[32m|STATISTICAL_TESTING_AGENT|\\nTo perform dimensionality reduction use |DIMENSION_REDUCTION_AGENT|\\nTo segment data \u001b[0m\n",
       "\u001b[32minto clusters use |CLUSTERING_AGENT|\\nTo build predictive models use |PREDICTIVE_MODELING_AGENT|\\nTo evaluate model\u001b[0m\n",
       "\u001b[32mperformance use |MODEL_EVALUATION_AGENT|\\nTo optimize hyperparameters use |HYPERPARAMETER_TUNING_AGENT|\\nTo handle \u001b[0m\n",
       "\u001b[32mimbalanced datasets use |CLASS_IMBALANCE_AGENT|\\nTo implement time series analysis use |TIME_SERIES_AGENT|\\nTo \u001b[0m\n",
       "\u001b[32mperform text analysis use |TEXT_ANALYTICS_AGENT|\\nTo extract insights from geospatial data use \u001b[0m\n",
       "\u001b[32m|GEOSPATIAL_ANALYSIS_AGENT|\\nTo process large datasets use |BIG_DATA_PROCESSING_AGENT|\\nTo create data pipelines \u001b[0m\n",
       "\u001b[32muse |DATA_PIPELINE_AGENT|\\nTo generate synthetic data use |SYNTHETIC_DATA_AGENT|\\nTo implement cross-validation use\u001b[0m\n",
       "\u001b[32m|CROSS_VALIDATION_AGENT|\\nTo interpret complex models use |MODEL_INTERPRETATION_AGENT|\\nTo detect data drift use \u001b[0m\n",
       "\u001b[32m|DATA_DRIFT_AGENT|\\nTo run A/B tests use |AB_TESTING_AGENT|\\nTo prepare data for machine learning use \u001b[0m\n",
       "\u001b[32m|ML_PREPROCESSING_AGENT|\\nTo create ensemble models use |ENSEMBLE_MODELING_AGENT|\\nTo perform anomaly detection use\u001b[0m\n",
       "\u001b[32m|ANOMALY_DETECTION_AGENT|\\nTo optimize SQL queries use |SQL_OPTIMIZATION_AGENT|\\nTo create interactive dashboards \u001b[0m\n",
       "\u001b[32muse |DASHBOARD_CREATION_AGENT|\\nTo extract features from images use |IMAGE_FEATURE_AGENT|\\nTo implement natural \u001b[0m\n",
       "\u001b[32mlanguage processing use |NLP_AGENT|\\nTo perform sentiment analysis use |SENTIMENT_ANALYSIS_AGENT|\\nTo do automated \u001b[0m\n",
       "\u001b[32mfeature selection use |FEATURE_SELECTION_AGENT|\\nTo generate reports automatically use \u001b[0m\n",
       "\u001b[32m|AUTOMATED_REPORTING_AGENT|\\nAlso include a reason and return output as JSON with the following structure with the \u001b[0m\n",
       "\u001b[32mreport name as per context given:\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"report\": \" |DATA_TYPES_AGENT|\", \"reason\": \"this is a report aboit \u001b[0m\n",
       "\u001b[32msales\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n#ONLY# JSON\\n'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'i want to have cross validation data '\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We use Gradio for a chat interface\n",
    "# prompt: I am want a plane to Rome then an auto to Paris\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval-framework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
